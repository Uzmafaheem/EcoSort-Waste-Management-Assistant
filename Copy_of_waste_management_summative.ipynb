{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uzmafaheem/EcoSort-Waste-Management-Assistant/blob/main/Copy_of_waste_management_summative.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2psHklGRjNS"
      },
      "source": [
        "# EcoSort Waste Management Assistant\n",
        "# Module 8 Summative Lab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L1jGlvHRjNV"
      },
      "source": [
        "## Overview\n",
        "\n",
        "You are a data scientist at \"EcoSort,\" a technology company that specializes in developing AI solutions for waste management. EcoSort has partnered with Metro City's waste management department to develop an intelligent waste management assistant that can help residents properly dispose of waste items so less time is spent sorting material at facilities.\n",
        "\n",
        "This assistant needs to:\n",
        "\n",
        "1. Identify waste materials from images uploaded by residents (CNN)\n",
        "2. Classify waste items based on text descriptions provided by residents (RNN/Transformer)\n",
        "3. Generate specific recycling instructions based on identified waste type and city policies (Generative Transformer with RAG)\n",
        "\n",
        "Your task is to build this integrated system using the RealWaste dataset along with generated text data that simulates real-world waste management operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHzCo330RjNW"
      },
      "source": [
        "## Part 1: Dataset Exploration and Preparation\n",
        "\n",
        "In this section, you will explore and prepare the datasets for your models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-3mzMwFRjNW"
      },
      "source": [
        "### 1.1 Load and Explore the RealWaste Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lauhxwjTRjNW"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMbkZ4Hy4bir"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/MyDrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNan440gBmRi"
      },
      "outputs": [],
      "source": [
        "# List all files/folders in MyDrive\n",
        "print(os.listdir(\"/content/MyDrive\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ekI_6dECb2m"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REn81ExxCghz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Check root of MyDrive\n",
        "print(os.listdir(\"/content/drive\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QvnIFEHC_KC"
      },
      "outputs": [],
      "source": [
        "image_dir = \"/content/drive/MyDrive/realwaste-main/RealWaste/\"\n",
        "description_file = \"/content/waste_descriptions.csv\"\n",
        "policy_file = \"/content/waste_policy_documents.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4BBLwa-DB7m"
      },
      "outputs": [],
      "source": [
        "categories = os.listdir(image_dir)\n",
        "print(\"Waste categories:\", categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHwNRu5D3PDm"
      },
      "outputs": [],
      "source": [
        "# Paths\n",
        "image_dir = \"/content/drive/MyDrive/realwaste-main/RealWaste/\"\n",
        "description_file = \"/content/waste_descriptions.csv\"\n",
        "policy_file = \"/content/waste_policy_documents.json\"\n",
        "\n",
        "# Load text descriptions\n",
        "descriptions_df = pd.read_csv(description_file)\n",
        "print(\"Sample descriptions:\")\n",
        "display(descriptions_df.head())\n",
        "\n",
        "# Load policy documents\n",
        "with open(policy_file, 'r') as f:\n",
        "    policies = json.load(f)\n",
        "print(\"Sample policy document:\")\n",
        "print(json.dumps(policies[0], indent=2))\n",
        "\n",
        "# Explore image dataset\n",
        "categories = os.listdir(image_dir)\n",
        "categories = [cat for cat in categories if os.path.isdir(os.path.join(image_dir, cat))]\n",
        "print(\"Waste categories:\", categories)\n",
        "\n",
        "# Count images per category\n",
        "category_counts = {cat: len(os.listdir(os.path.join(image_dir, cat))) for cat in categories}\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=list(category_counts.keys()), y=list(category_counts.values()))\n",
        "plt.title(\"Number of Images per Waste Category\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xlabel(\"Category\")\n",
        "plt.show()\n",
        "\n",
        "# Sample images inspection\n",
        "for cat in categories[:3]:  # just sample first 3 categories\n",
        "    sample_img_name = os.listdir(os.path.join(image_dir, cat))[0]\n",
        "    img = Image.open(os.path.join(image_dir, cat, sample_img_name))\n",
        "    print(f\"Category: {cat}, Image: {sample_img_name}, Size: {img.size}, Mode: {img.mode}\")\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR-vCTxIRjNY"
      },
      "source": [
        "### 1.2 Explore Text Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCUygCWdEC4r"
      },
      "outputs": [],
      "source": [
        "# Load CSV\n",
        "descriptions_df = pd.read_csv(description_file)\n",
        "\n",
        "# Quick look at the data\n",
        "print(\"First 5 rows of waste_descriptions.csv:\")\n",
        "print(descriptions_df.head())\n",
        "\n",
        "# Info about columns and missing values\n",
        "print(\"\\nDataFrame info:\")\n",
        "print(descriptions_df.info())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(descriptions_df.isnull().sum())\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(y='category', data=descriptions_df, order=descriptions_df['category'].value_counts().index)\n",
        "plt.title(\"Distribution of Waste Categories in Text Descriptions\")\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Waste Category\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "num_descriptions = len(descriptions_df)\n",
        "print(f\"Total number of waste descriptions: {num_descriptions}\")\n",
        "\n",
        "# Average length of descriptions (in words)\n",
        "descriptions_df['text_length'] = descriptions_df['description'].apply(lambda x: len(str(x).split()))\n",
        "avg_length = descriptions_df['text_length'].mean()\n",
        "print(f\"Average description length (words): {avg_length:.2f}\")\n",
        "\n",
        "# Vocabulary size (approximate)\n",
        "from collections import Counter\n",
        "all_words = ' '.join(descriptions_df['description'].astype(str)).lower().split()\n",
        "vocab = Counter(all_words)\n",
        "print(f\"Approximate vocabulary size: {len(vocab)}\")\n",
        "\n",
        "# Most common words\n",
        "print(\"Top 20 most common words:\")\n",
        "print(vocab.most_common(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfFfZIFREIrx"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(policy_file, 'r') as f:\n",
        "    policies = json.load(f)\n",
        "\n",
        "# Number of documents\n",
        "print(f\"Total number of policy documents: {len(policies)}\")\n",
        "\n",
        "# Preview the first document\n",
        "print(\"\\nSample policy document (formatted):\")\n",
        "print(json.dumps(policies[0], indent=2))\n",
        "\n",
        "\n",
        "#  Understand document structure\n",
        "\n",
        "# Assuming each policy document is a dictionary with keys like 'title', 'content', 'category', etc.\n",
        "keys = set()\n",
        "for doc in policies:\n",
        "    keys.update(doc.keys())\n",
        "print(\"\\nAll keys present in policy documents:\", keys)\n",
        "\n",
        "# Check distribution of categories (if 'category' key exists)\n",
        "categories = [doc.get('category', 'Unknown') for doc in policies]\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cat_df = pd.DataFrame({'category': categories})\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(y='category', data=cat_df, order=cat_df['category'].value_counts().index)\n",
        "plt.title(\"Distribution of Policy Document Categories\")\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Category\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#  Analyze text length and content\n",
        "\n",
        "# Example: length of content in words\n",
        "content_lengths = [len(doc.get('content','').split()) for doc in policies]\n",
        "print(f\"Average length of policy content (words): {sum(content_lengths)/len(content_lengths):.2f}\")\n",
        "print(f\"Minimum content length: {min(content_lengths)}, Maximum: {max(content_lengths)}\")\n",
        "\n",
        "# Optionally, print a short excerpt from first few documents\n",
        "print(\"\\nPolicy excerpts:\")\n",
        "for i, doc in enumerate(policies[:3]):\n",
        "    content = doc.get('content','')\n",
        "    print(f\"\\nDocument {i+1} excerpt:\", content[:300], \"...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj9uiWLuRjNZ"
      },
      "source": [
        "### 1.3 Create Data Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5z1AWpXzRjNZ"
      },
      "outputs": [],
      "source": [
        "# Run this code to setup the images properly into train, validation, and test sets\n",
        "# Set your data directory path - update this with your actual path\n",
        "import pathlib\n",
        "data_dir = pathlib.Path(\"/content/drive/MyDrive/realwaste-main/RealWaste\")\n",
        "\n",
        "#data_dir = pathlib.Path('RealWaste')\n",
        "\n",
        "# Parameters\n",
        "BATCH_SIZE = 32\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "\n",
        "# Calculate the total number of classes automatically from the directory structure\n",
        "num_classes = len([item for item in data_dir.glob('*') if item.is_dir()])\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# List all class folders\n",
        "class_names = sorted([item.name for item in data_dir.glob('*') if item.is_dir()])\n",
        "print(f\"Class names: {class_names}\")\n",
        "\n",
        "# Count all images\n",
        "image_count = len(list(data_dir.glob('*/*.jpg'))) + len(list(data_dir.glob('*/*.png')))\n",
        "print(f\"Total images found: {image_count}\")\n",
        "\n",
        "# Create a dataset using tf.keras.utils.image_dataset_from_directory\n",
        "# This will automatically split the data into training and validation sets\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,  # 20% for validation\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical',  # For one-hot encoded labels\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,  # 20% for validation\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical',  # For one-hot encoded labels\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Create a separate test dataset by taking part of the validation set\n",
        "# First, let's get the number of batches in the validation set\n",
        "val_batches = tf.data.experimental.cardinality(validation_ds)\n",
        "test_dataset = validation_ds.take(val_batches // 2)\n",
        "validation_ds = validation_ds.skip(val_batches // 2)\n",
        "\n",
        "print(f\"Number of training batches: {tf.data.experimental.cardinality(train_ds)}\")\n",
        "print(f\"Number of validation batches: {tf.data.experimental.cardinality(validation_ds)}\")\n",
        "print(f\"Number of test batches: {tf.data.experimental.cardinality(test_dataset)}\")\n",
        "\n",
        "# Configure dataset for performance\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "validation_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qvp2mUCOFxET"
      },
      "outputs": [],
      "source": [
        "descriptions_df = pd.read_csv(description_file)\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Quick check\n",
        "print(descriptions_df.head())\n",
        "\n",
        "\n",
        "#  Text cleaning function\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()  # lowercase\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)  # remove punctuation/special chars\n",
        "    text = re.sub(r'\\s+', ' ', text)  # remove extra spaces\n",
        "    return text.strip()\n",
        "\n",
        "descriptions_df['cleaned_description'] = descriptions_df['description'].apply(clean_text)\n",
        "\n",
        "\n",
        "#  Encode labels\n",
        "\n",
        "# Create a mapping from category names to integers\n",
        "category_list = sorted(descriptions_df['category'].unique())\n",
        "category_to_index = {cat:i for i, cat in enumerate(category_list)}\n",
        "descriptions_df['label'] = descriptions_df['category'].map(category_to_index)\n",
        "\n",
        "num_classes = len(category_list)\n",
        "print(f\"Number of categories: {num_classes}\")\n",
        "print(\"Category mapping:\", category_to_index)\n",
        "\n",
        "\n",
        "#  Tokenization & padding\n",
        "\n",
        "MAX_VOCAB_SIZE = 5000\n",
        "MAX_SEQUENCE_LENGTH = 50  # max words per description\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(descriptions_df['cleaned_description'])\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(descriptions_df['cleaned_description'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "print(\"Example sequence (padded):\")\n",
        "print(padded_sequences[0])\n",
        "\n",
        "\n",
        "# Train-test split\n",
        "\n",
        "X = padded_sequences\n",
        "y = tf.keras.utils.to_categorical(descriptions_df['label'], num_classes=num_classes)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Train samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
        "\n",
        "\n",
        "# create TensorFlow dataset\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_ds_text = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_ds_text = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQZaGuJpGVcu"
      },
      "outputs": [],
      "source": [
        "#  Imports\n",
        "\n",
        "import json\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "# 2 Load policy documents\n",
        "\n",
        "with open(policy_file, 'r') as f:\n",
        "    policies = json.load(f)\n",
        "\n",
        "\n",
        "# 3 Preprocess text\n",
        "# - lowercase, remove extra spaces, remove non-alphanumeric chars\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'\\s+', ' ', text)  # remove extra spaces/newlines\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)  # remove special characters\n",
        "    return text.strip()\n",
        "\n",
        "# Combine title + content for each document\n",
        "documents = []\n",
        "for doc in policies:\n",
        "    content = doc.get('document_text', '') # Use 'document_text' key\n",
        "    clean_text = preprocess_text(content)\n",
        "    documents.append(clean_text)\n",
        "\n",
        "print(f\"Total documents processed: {len(documents)}\")\n",
        "print(\"Sample processed document:\", documents[0][:300], \"...\")\n",
        "\n",
        "\n",
        "# 4Ô∏è Split documents into smaller chunks for retrieval\n",
        "\n",
        "CHUNK_SIZE = 150  # words per chunk\n",
        "doc_chunks = []\n",
        "\n",
        "for doc in documents:\n",
        "    words = doc.split()\n",
        "    for i in range(0, len(words), CHUNK_SIZE):\n",
        "        chunk = \" \".join(words[i:i+CHUNK_SIZE])\n",
        "        doc_chunks.append(chunk)\n",
        "\n",
        "print(f\"Total chunks created: {len(doc_chunks)}\")\n",
        "if len(doc_chunks) > 0:\n",
        "  print(\"Sample chunk:\", doc_chunks[0])\n",
        "else:\n",
        "  print(\"No chunks created.\")\n",
        "\n",
        "\n",
        "# Create embeddings\n",
        "\n",
        "# Load a pre-trained sentence transformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')  # lightweight, fast\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = model.encode(doc_chunks, show_progress_bar=True)\n",
        "embeddings = np.array(embeddings)\n",
        "\n",
        "print(\"Embeddings shape:\", embeddings.shape)\n",
        "\n",
        "\n",
        "#  Save chunks and embeddings (optional)\n",
        "\n",
        "with open(\"policy_chunks.pkl\", \"wb\") as f:\n",
        "    pickle.dump(doc_chunks, f)\n",
        "\n",
        "with open(\"policy_embeddings.npy\", \"wb\") as f:\n",
        "    np.save(f, embeddings)\n",
        "\n",
        "print(\"Chunks and embeddings saved successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcnO9HqoRjNZ"
      },
      "source": [
        "## Part 2: Waste Material Classification with CNN\n",
        "\n",
        "In this section, you will build a CNN model to classify waste materials from images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGuSWFkYRjNZ"
      },
      "source": [
        "### 2.1 Preprocess Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHw7IWbNRjNZ"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement image preprocessing\n",
        "# - Apply the preprocessing pipeline created earlier\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Assuming you already created train_ds, validation_ds, and test_dataset previously\n",
        "\n",
        "# 1Ô∏è‚É£ Normalize pixel values\n",
        "# CNNs train better when pixel values are in [0,1]\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "validation_ds = validation_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "test_dataset = test_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "# 2Ô∏è‚É£ (Optional) Data augmentation\n",
        "# Helps prevent overfitting and improves generalization\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "# Apply augmentation only to training dataset\n",
        "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "\n",
        "# 3Ô∏è‚É£ Optimize pipeline performance\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "validation_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Confirm preprocessing\n",
        "for images, labels in train_ds.take(1):\n",
        "    print(\"Image batch shape:\", images.shape)\n",
        "    print(\"Label batch shape:\", labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Atg_s1c5RjNa"
      },
      "source": [
        "### 2.2 Implement CNN Model with Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6HPFM1mRjNa"
      },
      "outputs": [],
      "source": [
        "# TODO: Select an appropriate base model and implement transfer learning\n",
        "# - Choose from MobileNet, EfficientNet, etc.\n",
        "# - Add custom classification layers for the 9 waste categories\n",
        "# - Configure loss function and metrics\n",
        "\n",
        "# Import necessary modules\n",
        "from tensorflow.keras import layers, models, optimizers, regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Number of waste classes (you can update if needed)\n",
        "NUM_CLASSES = len(class_names)  # or manually set to 9\n",
        "\n",
        "# 1Ô∏è‚É£ Choose a pretrained base model\n",
        "# EfficientNetB0 is light, accurate, and ideal for image classification tasks\n",
        "base_model = tf.keras.applications.EfficientNetB0(\n",
        "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
        "    include_top=False,  # exclude final dense layers\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# Freeze the base model to retain pretrained ImageNet features\n",
        "base_model.trainable = False\n",
        "\n",
        "# 2Ô∏è‚É£ Build the transfer learning model\n",
        "inputs = tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "# Preprocessing layer (EfficientNet expects specific input scaling)\n",
        "x = tf.keras.applications.efficientnet.preprocess_input(inputs)\n",
        "\n",
        "# Pass through base model\n",
        "x = base_model(x, training=False)\n",
        "\n",
        "# Global average pooling to reduce dimensions\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Optional dropout for regularization\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "# Final classification layer (softmax for multi-class)\n",
        "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "# Define model\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# 3Ô∏è‚É£ Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 4Ô∏è‚É£ Model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w55nRURdRjNa"
      },
      "source": [
        "### 2.3 Train and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6flDXl3RjNa"
      },
      "outputs": [],
      "source": [
        "# TODO: Train the CNN model\n",
        "# - Use appropriate batch size and epochs\n",
        "# - Implement regularization to prevent overfitting\n",
        "# - Monitor training and validation metrics\n",
        "\n",
        "# Import necessary callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# 1Ô∏è‚É£ Training configuration\n",
        "EPOCHS = 15\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Early stopping and learning rate scheduling to prevent overfitting\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=2,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 2Ô∏è‚É£ Train the model\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=validation_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 3Ô∏è‚É£ Evaluate on test dataset\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"\\n‚úÖ Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"‚úÖ Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "# 4Ô∏è‚É£ Visualize training performance\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2mXbdmGRjNa"
      },
      "outputs": [],
      "source": [
        "# TODO: Evaluate model performance\n",
        "# - Calculate accuracy on test set\n",
        "# - Generate confusion matrix\n",
        "# - Analyze error patterns\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# 1Ô∏è‚É£ Evaluate accuracy on test set\n",
        "test_loss, test_acc = model.evaluate(test_dataset, verbose=1)\n",
        "print(f\"\\n‚úÖ Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"‚úÖ Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "# 2Ô∏è‚É£ Generate predictions\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in test_dataset:\n",
        "    preds = model.predict(images)\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# 3Ô∏è‚É£ Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix - Waste Classification')\n",
        "plt.show()\n",
        "\n",
        "# 4Ô∏è‚É£ Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# 5Ô∏è‚É£ Analyze common misclassifications\n",
        "misclassified_indices = np.where(y_true != y_pred)[0]\n",
        "print(f\"\\nNumber of misclassified samples: {len(misclassified_indices)}\")\n",
        "\n",
        "# Optional: visualize a few misclassified examples\n",
        "for images, labels in test_dataset.take(1):\n",
        "    preds = model.predict(images)\n",
        "    pred_labels = np.argmax(preds, axis=1)\n",
        "    true_labels = np.argmax(labels.numpy(), axis=1)\n",
        "\n",
        "    mis_idx = np.where(pred_labels != true_labels)[0]\n",
        "    print(f\"Displaying {len(mis_idx)} misclassified examples from this batch...\")\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for i, idx in enumerate(mis_idx[:6]):  # show up to 6 examples\n",
        "        plt.subplot(2, 3, i + 1)\n",
        "        plt.imshow(images[idx].numpy().astype(\"uint8\"))\n",
        "        plt.title(f\"True: {class_names[true_labels[idx]]}\\nPred: {class_names[pred_labels[idx]]}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e93UA8VvRjNa"
      },
      "source": [
        "### 2.4 Fine-tune the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLTuotvjRjNa"
      },
      "outputs": [],
      "source": [
        "# TODO: Tune model parameters to improve performance\n",
        "# - Adjust learning rate\n",
        "# - Add regularization, dropout\n",
        "# - Modify architecture if needed\n",
        "from tensorflow.keras import layers, models, optimizers, regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "# 1Ô∏è‚É£ Unfreeze top layers of the base model for fine-tuning\n",
        "base_model.trainable = True\n",
        "\n",
        "# Optionally, freeze most layers and only fine-tune the top ones\n",
        "fine_tune_at = int(len(base_model.layers) * 0.7)  # unfreeze top 30%\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 2Ô∏è‚É£ Re-compile with a lower learning rate (important for fine-tuning)\n",
        "fine_tune_lr = 1e-5\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=fine_tune_lr),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 3Ô∏è‚É£ Add regularization and dropout if not already present\n",
        "# (You can rebuild the classifier head with dropout/regularization if needed)\n",
        "# The model architecture is already defined in cell H6HPFM1mRjNa.\n",
        "# We will fine-tune the existing 'model' object directly after unfreezing layers.\n",
        "\n",
        "# 4Ô∏è‚É£ Callbacks for stable training\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "\n",
        "# 5Ô∏è‚É£ Train the fine-tuned model\n",
        "history_fine = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=validation_ds,\n",
        "    epochs=10,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")\n",
        "\n",
        "# 6Ô∏è‚É£ Evaluate after fine-tuning\n",
        "test_loss, test_acc = model.evaluate(test_dataset, verbose=1)\n",
        "print(f\"\\n‚úÖ Fine-tuned Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"‚úÖ Fine-tuned Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOUzQm-ORjNa"
      },
      "source": [
        "## Part 3: Waste Description Classification\n",
        "\n",
        "In this section, you will build a text classification model to categorize waste based on descriptions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFvG5POxRjNa"
      },
      "source": [
        "### 3.1 Preprocess Text Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mkl2mkbTRjNa"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement text preprocessing\n",
        "# - Apply the text preprocessing pipeline created earlier\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the dataset\n",
        "descriptions_df = pd.read_csv(\"/content/waste_descriptions.csv\")\n",
        "print(\"‚úÖ Data loaded successfully!\")\n",
        "print(descriptions_df.head())\n",
        "\n",
        "# 1Ô∏è‚É£ Clean text function\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()  # lowercase\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)  # remove punctuation/special chars\n",
        "    text = re.sub(r'\\s+', ' ', text)  # remove extra spaces\n",
        "    return text.strip()\n",
        "\n",
        "# Apply cleaning\n",
        "descriptions_df['cleaned_description'] = descriptions_df['description'].apply(clean_text)\n",
        "\n",
        "# 2Ô∏è‚É£ Prepare labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "descriptions_df['label_encoded'] = label_encoder.fit_transform(descriptions_df['category'])\n",
        "num_classes = len(label_encoder.classes_)\n",
        "print(f\"‚úÖ Number of classes: {num_classes}\")\n",
        "print(f\"Class names: {label_encoder.classes_}\")\n",
        "\n",
        "# 3Ô∏è‚É£ Tokenization\n",
        "MAX_VOCAB_SIZE = 5000\n",
        "MAX_SEQUENCE_LENGTH = 50\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(descriptions_df['cleaned_description'])\n",
        "\n",
        "# Convert text to sequences and pad\n",
        "sequences = tokenizer.texts_to_sequences(descriptions_df['cleaned_description'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "# 4Ô∏è‚É£ Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    padded_sequences,\n",
        "    descriptions_df['label_encoded'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=descriptions_df['label_encoded']\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n",
        "\n",
        "# 5Ô∏è‚É£ Example check\n",
        "print(\"\\nExample cleaned + tokenized text:\")\n",
        "print(descriptions_df[['description', 'cleaned_description']].head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBO_6HtRRjNa"
      },
      "source": [
        "### 3.2 Implement Text Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgxh54VcRjNb"
      },
      "outputs": [],
      "source": [
        "# TODO: Choose and implement a text classification model\n",
        "# Option A: Traditional ML model (Naive Bayes, Random Forest, etc.)\n",
        "# Option B: Fine-tune a transformer-based model (BERT, DistilBERT, etc.)\n",
        "\n",
        "#optionA\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "\n",
        "# Parameters\n",
        "EMBEDDING_DIM = 128\n",
        "LSTM_UNITS = 128\n",
        "DROPOUT_RATE = 0.4\n",
        "\n",
        "# Build the model\n",
        "lstm_model = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=EMBEDDING_DIM, input_length=50),\n",
        "    Bidirectional(LSTM(LSTM_UNITS, return_sequences=False)),\n",
        "    Dropout(DROPOUT_RATE),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "lstm_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Summary\n",
        "lstm_model.summary()\n",
        "\n",
        "# Train\n",
        "history = lstm_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=8,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "loss, accuracy = lstm_model.evaluate(X_test, y_test)\n",
        "print(f\"\\n‚úÖ Test Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npFcIJCiRjNb"
      },
      "source": [
        "### 3.3 Train and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KrHYgHWRjNb"
      },
      "outputs": [],
      "source": [
        "# TODO: Train the text classification model\n",
        "# - Use appropriate training parameters\n",
        "# - Monitor training progress\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Train the model\n",
        "history = lstm_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = lstm_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\n‚úÖ Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Plot training history\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title(\"Model Accuracy Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title(\"Model Loss Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBnmw0EYRjNb"
      },
      "outputs": [],
      "source": [
        "# TODO: Evaluate model performance\n",
        "# - Calculate accuracy on test set\n",
        "# - Generate confusion matrix\n",
        "# - Analyze error patterns\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict on test data\n",
        "y_pred_probs = lstm_model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n‚úÖ Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "target_names = label_encoder.classes_\n",
        "print(\"\\nüìä Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "disp.plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix ‚Äî Waste Description Classifier (LSTM)\")\n",
        "plt.show()\n",
        "\n",
        "# Error analysis ‚Äî show top misclassified examples\n",
        "mismatch_indices = np.where(y_test != y_pred)[0]\n",
        "print(f\"\\n‚ùå Misclassified examples: {len(mismatch_indices)} / {len(y_test)}\")\n",
        "\n",
        "# Show a few examples\n",
        "for i in mismatch_indices[:5]:\n",
        "    print(f\"\\nüóëÔ∏è Description: {descriptions_df.iloc[i]['description']}\")\n",
        "    print(f\"Predicted: {target_names[y_pred[i]]} | Actual: {target_names[y_test.iloc[i]]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUrqcl15RjNb"
      },
      "source": [
        "### 3.4 Create Classification Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0P2ReB_RjNb"
      },
      "outputs": [],
      "source": [
        "# TODO: Create a function that takes a text description and returns the predicted waste category\n",
        "\n",
        "def classify_waste_description(description):\n",
        "    \"\"\"\n",
        "    Classifies a waste description into an appropriate category.\n",
        "\n",
        "    Args:\n",
        "        description (str): Text description of waste item\n",
        "\n",
        "    Returns:\n",
        "        str: Predicted waste category\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_waste_description(description):\n",
        "    \"\"\"\n",
        "    Classifies a waste description into an appropriate category (LSTM version).\n",
        "    \"\"\"\n",
        "    # 1Ô∏è‚É£ Clean text\n",
        "    def clean_text(text):\n",
        "        text = str(text).lower()\n",
        "        text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        return text.strip()\n",
        "\n",
        "    cleaned_text = clean_text(description)\n",
        "\n",
        "    # 2Ô∏è‚É£ Tokenize + pad\n",
        "    seq = tokenizer.texts_to_sequences([cleaned_text])\n",
        "    padded = pad_sequences(seq, maxlen=50, padding='post', truncating='post')\n",
        "\n",
        "    # 3Ô∏è‚É£ Predict\n",
        "    pred_probs = lstm_model.predict(padded)\n",
        "    pred_label = np.argmax(pred_probs, axis=1)[0]\n",
        "\n",
        "    # 4Ô∏è‚É£ Decode to category name\n",
        "    predicted_category = label_encoder.inverse_transform([pred_label])[0]\n",
        "\n",
        "    return predicted_category"
      ],
      "metadata": {
        "id": "07n_ryVkNcH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_desc = \"Empty soda can made of aluminum\"\n",
        "pred = classify_waste_description(test_desc)\n",
        "print(f\"üßæ Description: {test_desc}\\nüîç Predicted Category: {pred}\")"
      ],
      "metadata": {
        "id": "MR1GR8UFNokU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kV487HBRjNb"
      },
      "source": [
        "## Part 4: Recycling Instruction Generation with RAG\n",
        "\n",
        "In this section, you will implement a Retrieval-Augmented Generation (RAG) system to generate recycling instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piGWJKgiRjNb"
      },
      "source": [
        "### 4.1 Preprocess Documents for Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwZA_B6_RjNb"
      },
      "outputs": [],
      "source": [
        "# TODO: Prepare documents for retrieval\n",
        "# - Process policy documents and disposal instructions\n",
        "# - Create embeddings for efficient retrieval\n",
        "\n",
        "policy_file = \"/content/waste_policy_documents.json\"  # update path\n",
        "with open(policy_file, 'r') as f:\n",
        "    policies = json.load(f)\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(policies)} policy documents\")\n",
        "\n",
        "# Optional: inspect first document\n",
        "print(json.dumps(policies[0], indent=2))\n",
        "\n",
        "# 2Ô∏è‚É£ Preprocess text documents\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    text = ' '.join(text.split())  # remove extra spaces\n",
        "    return text\n",
        "\n",
        "# Flatten documents into a list of text snippets for retrieval\n",
        "policy_texts = []\n",
        "for doc in policies:\n",
        "    # Assuming each doc has a 'title' and 'content'\n",
        "    title = preprocess_text(doc.get('title', ''))\n",
        "    content = preprocess_text(doc.get('content', ''))\n",
        "    policy_texts.append(f\"{title}. {content}\")\n",
        "\n",
        "print(f\"‚úÖ Total processed documents/snippets: {len(policy_texts)}\")\n",
        "\n",
        "# 3Ô∏è‚É£ Create embeddings\n",
        "# Using a SentenceTransformer model for embeddings\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # lightweight & fast\n",
        "\n",
        "# Compute embeddings\n",
        "policy_embeddings = embedding_model.encode(policy_texts, show_progress_bar=True)\n",
        "\n",
        "# Convert to numpy array for efficient retrieval\n",
        "policy_embeddings = np.array(policy_embeddings)\n",
        "print(f\"‚úÖ Embeddings shape: {policy_embeddings.shape}\")\n",
        "\n",
        "# 4Ô∏è‚É£ Simple retrieval function (cosine similarity)\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def retrieve_policy(query, top_k=3):\n",
        "    \"\"\"\n",
        "    Retrieve top-k relevant policy snippets for a given query.\n",
        "    \"\"\"\n",
        "    query_emb = embedding_model.encode([preprocess_text(query)])\n",
        "    similarities = cosine_similarity(query_emb, policy_embeddings)[0]\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "    top_texts = [policy_texts[i] for i in top_indices]\n",
        "    return top_texts\n",
        "\n",
        "# Example usage\n",
        "query = \"How should I dispose of a plastic bottle?\"\n",
        "top_docs = retrieve_policy(query, top_k=2)\n",
        "print(\"\\nTop retrieved policy snippets:\")\n",
        "for i, doc in enumerate(top_docs):\n",
        "    print(f\"{i+1}. {doc}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgzotuLDRjNb"
      },
      "source": [
        "### 4.2 Implement RAG-based System"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentence-transformers faiss-cpu -q\n"
      ],
      "metadata": {
        "id": "A90ZVvGeOKbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3Db6G58RjNb"
      },
      "outputs": [],
      "source": [
        "# TODO: Select a pre-trained language model and implement RAG\n",
        "# - Choose an appropriate language model\n",
        "# - Create a retrieval mechanism\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# 1Ô∏è‚É£ Load a pre-trained generative model (T5/Flan-T5 for instruction generation)\n",
        "model_name = \"google/flan-t5-base\"  # lightweight yet powerful\n",
        "tokenizer_rag = AutoTokenizer.from_pretrained(model_name)\n",
        "model_rag = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# 2Ô∏è‚É£ RAG helper function\n",
        "def generate_recycling_instructions(waste_description, top_k=3, max_length=150):\n",
        "    \"\"\"\n",
        "    Generates recycling instructions for a waste item using RAG.\n",
        "\n",
        "    Args:\n",
        "        waste_description (str): Description of the waste item\n",
        "        top_k (int): Number of retrieved policy snippets to condition generation\n",
        "        max_length (int): Max length of generated instruction\n",
        "\n",
        "    Returns:\n",
        "        str: Generated recycling instructions\n",
        "    \"\"\"\n",
        "    # Retrieve top-k policy documents\n",
        "    retrieved_docs = retrieve_policy(waste_description, top_k=top_k)\n",
        "\n",
        "    # Combine waste description + retrieved policies into prompt\n",
        "    prompt = f\"Item: {waste_description}\\n\\nPolicies:\\n\" + \"\\n\".join(retrieved_docs) + \"\\n\\nInstruction:\"\n",
        "\n",
        "    # Tokenize input\n",
        "    inputs = tokenizer_rag(prompt, return_tensors=\"pt\", truncation=True)\n",
        "\n",
        "    # Generate output\n",
        "    outputs = model_rag.generate(\n",
        "        **inputs,\n",
        "        max_length=max_length,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Decode generated text\n",
        "    instruction = tokenizer_rag.decode(outputs[0], skip_special_tokens=True)\n",
        "    return instruction\n",
        "\n",
        "# 3Ô∏è‚É£ Example usage\n",
        "example_description = \"Broken glass bottle\"\n",
        "instruction = generate_recycling_instructions(example_description, top_k=2)\n",
        "print(f\"\\nüóëÔ∏è Waste Item: {example_description}\\nüìÑ Recycling Instruction: {instruction}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv-tCvY8RjNb"
      },
      "source": [
        "### 4.3 Adjust and Evaluate the System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qX5AkI7LRjNh"
      },
      "outputs": [],
      "source": [
        "# TODO: Train the RAG-based system\n",
        "# - Adjust sampling methods/parameters\n",
        "\n",
        "generation_params = {\n",
        "    \"max_length\": 150,\n",
        "    \"num_beams\": 4,\n",
        "    \"temperature\": 0.7,  # controls creativity\n",
        "    \"top_p\": 0.9,        # nucleus sampling\n",
        "    \"early_stopping\": True\n",
        "}\n",
        "\n",
        "# 2Ô∏è‚É£ Function to generate instruction with adjustable parameters\n",
        "def generate_instruction_rag(description, top_k=3, params=generation_params):\n",
        "    retrieved_docs = retrieve_policy(description, top_k=top_k)\n",
        "    prompt = f\"Item: {description}\\n\\nPolicies:\\n\" + \"\\n\".join(retrieved_docs) + \"\\n\\nInstruction:\"\n",
        "\n",
        "    inputs = tokenizer_rag(prompt, return_tensors=\"pt\", truncation=True)\n",
        "\n",
        "    outputs = model_rag.generate(**inputs, **params)\n",
        "    instruction = tokenizer_rag.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return instruction\n",
        "\n",
        "# 3Ô∏è‚É£ Evaluate on sample test set\n",
        "test_descriptions = [\n",
        "    \"Plastic soda bottle\",\n",
        "    \"Broken brown glass jar\",\n",
        "    \"Used aluminum can\",\n",
        "    \"Food waste scraps\"\n",
        "]\n",
        "\n",
        "for desc in test_descriptions:\n",
        "    instr = generate_instruction_rag(desc, top_k=2)\n",
        "    print(f\"\\nüóëÔ∏è Waste Item: {desc}\\nüìÑ Recycling Instruction: {instr}\")\n",
        "\n",
        "# 4Ô∏è‚É£ Optional: Evaluate quality metrics\n",
        "# For production, you can compare generated instructions against a reference dataset\n",
        "# using BLEU, ROUGE, or human evaluation.\n",
        "\n",
        "# Example (pseudo-code, requires reference instructions):\n",
        "# from rouge_score import rouge_scorer\n",
        "# scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "# score = scorer.score(reference_text, generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3RfCq24RjNh"
      },
      "outputs": [],
      "source": [
        "# TODO: Evaluate the quality of generated instructions\n",
        "# - Test with various waste categories\n",
        "# - Assess relevance and accuracy\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Sample test waste descriptions for evaluation\n",
        "test_descriptions = [\n",
        "    \"Plastic soda bottle\",\n",
        "    \"Broken brown glass jar\",\n",
        "    \"Used aluminum can\",\n",
        "    \"Food waste scraps\",\n",
        "    \"Cardboard box\",\n",
        "    \"Green glass wine bottle\"\n",
        "]\n",
        "\n",
        "# Reference categories (for categorical consistency check)\n",
        "reference_categories = [\n",
        "    \"plastic\",\n",
        "    \"brown-glass\",\n",
        "    \"metal\",\n",
        "    \"biological\",\n",
        "    \"cardboard\",\n",
        "    \"green-glass\"\n",
        "]\n",
        "\n",
        "# 1Ô∏è‚É£ Generate instructions and predict categories\n",
        "generated_instructions = []\n",
        "predicted_categories = []\n",
        "\n",
        "for desc in test_descriptions:\n",
        "    instr = generate_instruction_rag(desc, top_k=2)\n",
        "    generated_instructions.append(instr)\n",
        "\n",
        "    # Optional: use text classifier to predict category from generated instruction\n",
        "    cat = classify_waste_description(desc)\n",
        "    predicted_categories.append(cat)\n",
        "\n",
        "    print(f\"\\nüóëÔ∏è Waste Item: {desc}\")\n",
        "    print(f\"üìÑ Generated Instruction: {instr}\")\n",
        "    print(f\"üè∑Ô∏è Predicted Category: {cat}\")\n",
        "\n",
        "# 2Ô∏è‚É£ Evaluate category consistency\n",
        "consistency = accuracy_score(reference_categories, predicted_categories)\n",
        "print(f\"\\n‚úÖ Category Consistency Accuracy: {consistency:.4f}\")\n",
        "\n",
        "# 3Ô∏è‚É£ Optional: Automated text quality metrics (requires reference instructions)\n",
        "# from rouge_score import rouge_scorer\n",
        "# scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "# for gen, ref in zip(generated_instructions, reference_instructions):\n",
        "#     score = scorer.score(ref, gen)\n",
        "#     print(score)\n",
        "\n",
        "# 4Ô∏è‚É£ Manual inspection\n",
        "# Review the instructions to ensure:\n",
        "# - Correct disposal method\n",
        "# - Material-specific instructions\n",
        "# - Relevance to municipal policies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfep5M1BRjNi"
      },
      "source": [
        "### 4.4 Create Instruction Generation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqy4abs1RjNi"
      },
      "outputs": [],
      "source": [
        "# TODO: Create a function that takes a waste category and generates recycling instructions\n",
        "\n",
        "def generate_recycling_instructions(waste_category):\n",
        "    \"\"\"\n",
        "    Generates detailed recycling instructions for a given waste category.\n",
        "\n",
        "    Args:\n",
        "        waste_category (str): Waste category\n",
        "\n",
        "    Returns:\n",
        "        str: Detailed recycling instructions\n",
        "        list: Relevant policy documents\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_recycling_instructions(waste_category, top_k=3, max_length=150):\n",
        "    \"\"\"\n",
        "    Generates detailed recycling instructions for a given waste category.\n",
        "\n",
        "    Args:\n",
        "        waste_category (str): Waste category or description\n",
        "        top_k (int): Number of top policy documents to retrieve\n",
        "        max_length (int): Maximum length of generated instruction\n",
        "\n",
        "    Returns:\n",
        "        instruction (str): Detailed recycling instructions\n",
        "        retrieved_docs (list): List of relevant policy snippets\n",
        "    \"\"\"\n",
        "    # 1Ô∏è‚É£ Retrieve top-k relevant policy documents\n",
        "    retrieved_docs = retrieve_policy(waste_category, top_k=top_k)\n",
        "\n",
        "    # 2Ô∏è‚É£ Construct prompt for RAG generator\n",
        "    prompt = f\"Waste Category/Item: {waste_category}\\n\\nPolicies:\\n\" + \\\n",
        "             \"\\n\".join(retrieved_docs) + \"\\n\\nInstruction:\"\n",
        "\n",
        "    # 3Ô∏è‚É£ Tokenize and generate instruction\n",
        "    inputs = tokenizer_rag(prompt, return_tensors=\"pt\", truncation=True)\n",
        "    outputs = model_rag.generate(\n",
        "        **inputs,\n",
        "        max_length=max_length,\n",
        "        num_beams=4,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # 4Ô∏è‚É£ Decode generated text\n",
        "    instruction = tokenizer_rag.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return instruction, retrieved_docs"
      ],
      "metadata": {
        "id": "-EcEHXkWPAxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zkj_HTRRjNi"
      },
      "source": [
        "## Part 5: Integrated Waste Management Assistant\n",
        "\n",
        "In this section, you will integrate all three models into a unified waste management assistant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Znk62hFRjNi"
      },
      "source": [
        "### 5.1 Design Integration Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj_U_JbZRjNi"
      },
      "outputs": [],
      "source": [
        "# TODO: Design an architecture that integrates all three models\n",
        "# - Create interfaces between components\n",
        "# - Handle input/output flow\n",
        "\n",
        "def eco_sort_assistant(image=None, text_description=None, top_k=3):\n",
        "    \"\"\"\n",
        "    Integrated assistant for waste management.\n",
        "\n",
        "    Args:\n",
        "        image: Path to waste image (optional)\n",
        "        text_description (str): Text description (optional)\n",
        "        top_k (int): Number of retrieved policies for RAG\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'predicted_category': str,\n",
        "            'recycling_instructions': str,\n",
        "            'retrieved_policies': list\n",
        "        }\n",
        "    \"\"\"\n",
        "    # 1Ô∏è‚É£ Predict category\n",
        "    category_from_image = None\n",
        "    category_from_text = None\n",
        "\n",
        "    if image is not None:\n",
        "        # Preprocess & predict using CNN\n",
        "        category_from_image = classify_waste_image(image)  # You need a CNN helper function\n",
        "    if text_description is not None:\n",
        "        # Predict using text classifier\n",
        "        category_from_text = classify_waste_description(text_description)\n",
        "\n",
        "    # 2Ô∏è‚É£ Resolve category\n",
        "    if category_from_image and category_from_text:\n",
        "        # Example logic: prefer image prediction if available\n",
        "        predicted_category = category_from_image\n",
        "    elif category_from_image:\n",
        "        predicted_category = category_from_image\n",
        "    elif category_from_text:\n",
        "        predicted_category = category_from_text\n",
        "    else:\n",
        "        predicted_category = \"Unknown\"\n",
        "\n",
        "    # 3Ô∏è‚É£ Generate recycling instructions\n",
        "    if predicted_category != \"Unknown\":\n",
        "        instructions, retrieved_docs = generate_recycling_instructions(predicted_category, top_k=top_k)\n",
        "    else:\n",
        "        instructions, retrieved_docs = \"Cannot determine category\", []\n",
        "\n",
        "    # 4Ô∏è‚É£ Return results\n",
        "    return {\n",
        "        'predicted_category': predicted_category,\n",
        "        'recycling_instructions': instructions,\n",
        "        'retrieved_policies': retrieved_docs\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVKgKn85RjNi"
      },
      "source": [
        "### 5.2 Implement Integrated Assistant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJYkJ8LIRjNi"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement the integrated waste management assistant\n",
        "\n",
        "def waste_management_assistant(input_data, input_type=\"image\"):\n",
        "    \"\"\"\n",
        "    Integrated waste management assistant that processes either images or text descriptions\n",
        "    and returns waste classification and recycling instructions.\n",
        "\n",
        "    Args:\n",
        "        input_data: Either an image file path/array or a text description\n",
        "        input_type (str): Type of input - \"image\" or \"text\"\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing waste category, confidence, and recycling instructions\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def waste_management_assistant(input_data, input_type=\"image\", top_k=3, cnn_model=None):\n",
        "    \"\"\"\n",
        "    Integrated waste management assistant that processes either images or text descriptions\n",
        "    and returns waste classification and recycling instructions.\n",
        "\n",
        "    Args:\n",
        "        input_data: Either an image file path/array or a text description\n",
        "        input_type (str): Type of input - \"image\" or \"text\"\n",
        "        top_k (int): Number of policy documents to retrieve for instruction generation\n",
        "        cnn_model: The trained CNN model for image classification\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'predicted_category': str,\n",
        "            'confidence': float (if available, else None),\n",
        "            'recycling_instructions': str,\n",
        "            'retrieved_policies': list\n",
        "        }\n",
        "    \"\"\"\n",
        "    predicted_category = None\n",
        "    confidence = None\n",
        "\n",
        "    # 1Ô∏è‚É£ Predict category from image\n",
        "    if input_type == \"image\":\n",
        "        if cnn_model is None:\n",
        "            return {\"error\": \"CNN model not provided for image input.\"}\n",
        "\n",
        "        # Preprocess image for CNN\n",
        "        from tensorflow.keras.preprocessing import image as keras_image\n",
        "        import numpy as np\n",
        "\n",
        "        img = keras_image.load_img(input_data, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "        img_array = keras_image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0) / 255.0  # normalize\n",
        "\n",
        "        # Predict\n",
        "        pred_probs = cnn_model.predict(img_array)\n",
        "        pred_index = np.argmax(pred_probs)\n",
        "        predicted_category = class_names[pred_index]\n",
        "        confidence = float(np.max(pred_probs))\n",
        "\n",
        "    # 2Ô∏è‚É£ Predict category from text\n",
        "    elif input_type == \"text\":\n",
        "        predicted_category = classify_waste_description(input_data)\n",
        "        confidence = None  # could add probability if classifier returns it\n",
        "\n",
        "    else:\n",
        "        return {\"error\": \"Invalid input_type. Choose 'image' or 'text'\"}\n",
        "\n",
        "    # 3Ô∏è‚É£ Generate recycling instructions using RAG\n",
        "    if predicted_category:\n",
        "        instructions, retrieved_docs = generate_recycling_instructions(predicted_category, top_k=top_k)\n",
        "    else:\n",
        "        instructions = \"Unable to determine category\"\n",
        "        retrieved_docs = []\n",
        "\n",
        "    # 4Ô∏è‚É£ Return results\n",
        "    return {\n",
        "        'predicted_category': predicted_category,\n",
        "        'confidence': confidence,\n",
        "        'recycling_instructions': instructions,\n",
        "        'retrieved_policies': retrieved_docs\n",
        "    }"
      ],
      "metadata": {
        "id": "KykIvJIyPw_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Image input\n",
        "#result_img = waste_management_assistant(\"/content/RealWaste/plastic/bottle1.jpg\", input_type=\"image\")\n",
        "#print(result_img)\n",
        "\n",
        "# Example 2: Text description input\n",
        "result_text = waste_management_assistant(\"Broken green wine bottle\", input_type=\"text\")\n",
        "print(result_text)"
      ],
      "metadata": {
        "id": "U6R9frk8P5D_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbav93z8RjNi"
      },
      "source": [
        "### 5.3 Evaluate the Integrated System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mj1IlIljRjNi"
      },
      "outputs": [],
      "source": [
        "# TODO: Evaluate the integrated system on test cases\n",
        "# - Test with images from test dataset\n",
        "# - Test with text descriptions from test dataset\n",
        "# - Assess overall performance\n",
        "\n",
        "import random\n",
        "import tensorflow as tf # Import tensorflow\n",
        "from tensorflow import keras # Import keras\n",
        "\n",
        "# 1Ô∏è‚É£ Evaluate on a few sample test images\n",
        "print(\"üîπ Testing on image inputs from test dataset:\")\n",
        "test_image_paths = []\n",
        "for batch in test_dataset.take(3):  # take 3 batches as example\n",
        "    images, labels = batch\n",
        "    for i in range(min(3, images.shape[0])):  # take up to 3 images per batch\n",
        "        # Save temporary image to file (needed for keras load_img)\n",
        "        temp_img_path = f\"temp_img_{i}.png\"\n",
        "        keras.preprocessing.image.save_img(temp_img_path, images[i].numpy())\n",
        "        test_image_paths.append(temp_img_path)\n",
        "\n",
        "for img_path in test_image_paths:\n",
        "    # Pass the trained CNN model ('model') for image input\n",
        "    result = waste_management_assistant(img_path, input_type=\"image\", cnn_model=model)\n",
        "    print(f\"\\nImage: {img_path}\")\n",
        "    print(f\"Predicted Category: {result['predicted_category']} | Confidence: {result['confidence']:.2f}\")\n",
        "    print(f\"Recycling Instructions: {result['recycling_instructions']}\")\n",
        "    print(f\"Retrieved Policies: {len(result['retrieved_policies'])} documents used\")\n",
        "\n",
        "# 2Ô∏è‚É£ Evaluate on text descriptions\n",
        "print(\"\\nüîπ Testing on text description inputs:\")\n",
        "sample_texts = random.sample(list(descriptions_df['description']), 5)  # 5 random test descriptions\n",
        "\n",
        "for text in sample_texts:\n",
        "    result = waste_management_assistant(text, input_type=\"text\")\n",
        "    print(f\"\\nText: {text}\")\n",
        "    print(f\"Predicted Category: {result['predicted_category']}\")\n",
        "    print(f\"Recycling Instructions: {result['recycling_instructions']}\")\n",
        "    print(f\"Retrieved Policies: {len(result['retrieved_policies'])} documents used\")\n",
        "\n",
        "# 3Ô∏è‚É£ Optional: Measure overall performance\n",
        "# - For images: compare predicted_category with true labels in test_dataset\n",
        "# - For text: compare predicted_category with true categories in descriptions_df\n",
        "# - Calculate accuracy and identify misclassified cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3w34n-1RjNi"
      },
      "source": [
        "## Submission Guidelines\n",
        "\n",
        "1. Make sure all code cells are properly commented and annotated\n",
        "2. Ensure that all functions are implemented and working correctly\n",
        "3. Verify that all evaluation metrics are calculated and analyzed\n",
        "4. Double-check that the integrated system works as expected\n",
        "5. Submit your completed and annotated Jupyter notebook file\n",
        "\n",
        "Remember to demonstrate your understanding of the underlying concepts and provide justification for your design decisions throughout the notebook."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}